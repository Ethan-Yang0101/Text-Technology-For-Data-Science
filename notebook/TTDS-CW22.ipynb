{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from stemming.porter2 import stem\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stop_words(file_name):\n",
    "    stop_words = []\n",
    "    with open(file_name, 'r', encoding='UTF-8') as f:\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '')\n",
    "            stop_words.append(line)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, stop_words):\n",
    "    tokens = re.compile(r'[a-zA-Z0-9]+', re.I).findall(text)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    tokens = [stem(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def building_token_corpora_dict(file_name, stop_words):\n",
    "    file = pd.read_csv(file_name, sep='\\t', header=None)\n",
    "    token_corpora_dict = {}\n",
    "    corpora_tokens = {}\n",
    "    for index in range(len(file)):\n",
    "        corpora_name = file.iloc[index][0]\n",
    "        text = file.iloc[index][1]\n",
    "        tokens = preprocess_text(text, stop_words)\n",
    "        if corpora_name not in token_corpora_dict:\n",
    "            token_corpora_dict[corpora_name] = []\n",
    "        if corpora_name not in corpora_tokens:\n",
    "            corpora_tokens[corpora_name] = []\n",
    "        token_corpora_dict[corpora_name].append(tokens)\n",
    "    for corpora_name in token_corpora_dict:\n",
    "        tokens = token_corpora_dict[corpora_name]\n",
    "        tokens = [token for row in tokens for token in row]\n",
    "        tokens = list(set(tokens))\n",
    "        corpora_tokens[corpora_name] = tokens\n",
    "    return token_corpora_dict, corpora_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_term_mutual_chi_components(term, target_corpus, other_corpus):\n",
    "    N = len(target_corpus) + len(other_corpus)\n",
    "    N11 = sum([1 for doc in target_corpus if term in doc])\n",
    "    N01 = len(target_corpus) - N11\n",
    "    N10 = sum([1 for doc in other_corpus if term in doc])\n",
    "    N00 = len(other_corpus) - N10\n",
    "    N1x, Nx1 = N11 + N10, N11 + N01\n",
    "    N0x, Nx0 = N00 + N01, N00 + N10\n",
    "    components = tuple([N, N11, N01, N10, N00, N1x, Nx1, N0x, Nx0])\n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_term_mutual_infomation(term, components):\n",
    "    N, N11, N01, N10, N00, N1x, Nx1, N0x, Nx0 = components\n",
    "    com1 = np.log2(N*N11 / (N1x*Nx1)) if N*N11 != 0 and N1x*Nx1 != 0 else 0\n",
    "    com2 = np.log2(N*N01 / (N0x*Nx1)) if N*N01 != 0 and N0x*Nx1 != 0 else 0\n",
    "    com3 = np.log2(N*N10 / (N1x*Nx0)) if N*N10 != 0 and N1x*Nx0 != 0 else 0\n",
    "    com4 = np.log2(N*N00 / (N0x*Nx0)) if N*N00 != 0 and N0x*Nx0 != 0 else 0\n",
    "    mutual_info = (N11/N)*com1 + (N01/N)*com2 + (N10/N)*com3 + (N00/N)*com4\n",
    "    return mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_term_chi_square_score(term, components):\n",
    "    N, N11, N01, N10, N00, N1x, Nx1, N0x, Nx0 = components\n",
    "    num = Nx1 * N1x * Nx0 * N0x\n",
    "    chi_square = N * ((N11*N00-N10*N01) ** 2) / num if num != 0 else 0\n",
    "    return chi_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_analysis_by_mutual_chi(token_corpora_dict, corpora_tokens):\n",
    "    corpus_names = [['Quran', 'OT', 'NT'], ['OT', 'Quran', 'NT'], ['NT', 'Quran', 'OT']]\n",
    "    corpus_mutual_chi = {'Quran': {}, 'OT': {}, 'NT': {}}\n",
    "    for corpus in corpus_names:\n",
    "        term_mutual_info, term_chi_square = [], []\n",
    "        target_corpus = token_corpora_dict[corpus[0]]\n",
    "        other_corpus = token_corpora_dict[corpus[1]] + token_corpora_dict[corpus[2]]\n",
    "        for term in corpora_tokens[corpus[0]]:\n",
    "            components = compute_term_mutual_chi_components(term, target_corpus, other_corpus)\n",
    "            mutual_info = compute_term_mutual_infomation(term, components)\n",
    "            chi_square = compute_term_chi_square_score(term, components)\n",
    "            term_mutual_info.append([term, mutual_info])\n",
    "            term_chi_square.append([term, chi_square])\n",
    "        term_mutual_info = sorted(term_mutual_info, key=lambda x: x[1], reverse=True)\n",
    "        term_chi_square = sorted(term_chi_square, key=lambda x: x[1], reverse=True)\n",
    "        corpus_mutual_chi[corpus[0]]['mutual_info'] = term_mutual_info[:10]\n",
    "        corpus_mutual_chi[corpus[0]]['chi_square'] = term_chi_square[:10]\n",
    "    return corpus_mutual_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_top_10_mutual_chi(corpus_mutual_chi):\n",
    "    with open('mutual_chi.txt', 'w', encoding='utf-8', newline='') as f:\n",
    "        headers, contents = [], []\n",
    "        writer = csv.writer(f)\n",
    "        for key1 in corpus_mutual_chi:\n",
    "            for key2 in corpus_mutual_chi[key1]:\n",
    "                header = key1 + ':' + key2\n",
    "                headers.append(header)\n",
    "                content = corpus_mutual_chi[key1][key2]\n",
    "                content = [str([row[0], round(row[1], 4)]) for row in content]\n",
    "                contents.append(content)\n",
    "        contents = np.array(contents).T.tolist()\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(contents)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = read_stop_words('./englishST1.txt')\n",
    "token_corpora_dict, corpora_tokens = building_token_corpora_dict('./train_and_dev1.tsv', stop_words)\n",
    "corpus_mutual_chi = token_analysis_by_mutual_chi(token_corpora_dict, corpora_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_top_10_mutual_chi(corpus_mutual_chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top3_topic_and_top10_score(corpora_texts, dictionary, lda):\n",
    "    all_topic_score_list = []\n",
    "    for text in corpora_texts:\n",
    "        bow = dictionary.doc2bow(text)\n",
    "        all_topic_score_list.append(lda.get_document_topics(bow=bow))\n",
    "    top3_topic_scores = []\n",
    "    topic_ids, avg_scores = compute_avg_score_topic_id(all_topic_score_list)\n",
    "    topic_ids, avg_scores = topic_ids[:3], avg_scores[:3]\n",
    "    for topic_id, avg_score in zip(topic_ids, avg_scores):\n",
    "        top3_topic_scores.append([topic_id, avg_score])\n",
    "    top_10_tokens = []\n",
    "    for topic_score in top3_topic_scores:\n",
    "        top_10_tokens.append(lda.show_topic(topic_score[0]))\n",
    "    return top3_topic_scores, top_10_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_score_topic_id(all_topic_score_list):\n",
    "    topic_scores = [0] * 20\n",
    "    for doc_topic_scores in all_topic_score_list:\n",
    "        for (topic_id, topic_score) in doc_topic_scores:\n",
    "            topic_scores[topic_id] += topic_score\n",
    "    avg_scores = np.array(topic_scores) / len(all_topic_score_list)\n",
    "    topic_ids = np.argsort(avg_scores)[::-1].tolist()\n",
    "    avg_scores = avg_scores[topic_ids].tolist()\n",
    "    return topic_ids, avg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_topic_analysis(token_corpora_dict):\n",
    "    quran_texts = token_corpora_dict['Quran']\n",
    "    ot_texts = token_corpora_dict['OT']\n",
    "    nt_texts = token_corpora_dict['NT']\n",
    "    texts = quran_texts + ot_texts + nt_texts\n",
    "    dictionary = Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    lda = LdaModel(corpus, id2word=dictionary, num_topics=20, random_state=1000)\n",
    "    quran_topic_scores, quran_tokens = compute_top3_topic_and_top10_score(\n",
    "        quran_texts, dictionary, lda)\n",
    "    ot_topic_scores, ot_tokens = compute_top3_topic_and_top10_score(\n",
    "        ot_texts, dictionary, lda)\n",
    "    nt_topic_scores, nt_tokens = compute_top3_topic_and_top10_score(\n",
    "        nt_texts, dictionary, lda)\n",
    "    results = {'quran_topic_scores': quran_topic_scores,\n",
    "               'quran_tokens': quran_tokens,\n",
    "               'ot_topic_scores': ot_topic_scores,\n",
    "               'ot_tokens': ot_tokens,\n",
    "               'nt_topic_scores': nt_topic_scores,\n",
    "               'nt_tokens': nt_tokens}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_top3_topics_and_top10_tokens(quran_topic_scores, quran_tokens,ot_topic_scores,\n",
    "                                       ot_tokens, nt_topic_scores, nt_tokens):\n",
    "    with open('lda_results.txt', 'w', encoding='utf-8') as f:\n",
    "        f.write(\"Quran top 3 topic scores and top 10 tokens for each topic\\n\")\n",
    "        for index, topic_score in enumerate(quran_topic_scores):\n",
    "            f.write(str(topic_score) + \"\\n\")\n",
    "            f.write(str(quran_tokens[index]) + \"\\n\")\n",
    "        f.write(\"OT top 3 topic scores and top 10 tokens for each topic\\n\")\n",
    "        for index, topic_score in enumerate(ot_topic_scores):\n",
    "            f.write(str(topic_score) + \"\\n\")\n",
    "            f.write(str(ot_tokens[index]) + \"\\n\")\n",
    "        f.write(\"NT top 3 topic scores and top 10 tokens for each topic\\n\")\n",
    "        for index, topic_score in enumerate(nt_topic_scores):\n",
    "            f.write(str(topic_score) + \"\\n\")\n",
    "            f.write(str(nt_tokens[index]) + \"\\n\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = read_stop_words('./englishST.txt')\n",
    "token_corpora_dict, corpora_tokens = building_token_corpora_dict('./train_and_dev.tsv', stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = lda_topic_analysis(token_corpora_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_top3_topics_and_top10_tokens(**results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
