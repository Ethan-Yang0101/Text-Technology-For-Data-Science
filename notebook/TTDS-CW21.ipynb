{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_of_rel_doc(query_table, rel_table, cutoff):\n",
    "    target_table = query_table[:cutoff]\n",
    "    number = sum(target_table['doc_number'].isin(rel_table['doc_id']))\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AP_for_query(query_table, rel_table):\n",
    "    AP_result = 0\n",
    "    rel_docnums = rel_table['doc_id'].tolist()\n",
    "    query_docnums = query_table['doc_number'].tolist()\n",
    "    for index in range(len(query_docnums)):\n",
    "        relevance = 1 if query_docnums[index] in rel_docnums else 0\n",
    "        if relevance:\n",
    "            cutoff = index + 1\n",
    "            precision = compute_num_of_rel_doc(query_table, rel_table, cutoff) / cutoff\n",
    "            AP_result += relevance * precision\n",
    "    AP_result = AP_result / len(rel_table)\n",
    "    return AP_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DCG_for_query(relevance_list):\n",
    "    DCG_result = relevance_list[0]\n",
    "    for index in range(1, len(relevance_list)):\n",
    "        DCG_result += relevance_list[index] / np.log2(index+1)\n",
    "    return DCG_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nDCG_for_query(query_table, rel_table, cutoff):\n",
    "    target_table = query_table[:cutoff]\n",
    "    rel_docnums = rel_table['doc_id'].tolist()\n",
    "    query_docnums = target_table['doc_number'].tolist()\n",
    "    relevance_list = []\n",
    "    for index in range(len(query_docnums)):\n",
    "        doc_number = query_docnums[index]\n",
    "        if doc_number in rel_docnums:\n",
    "            relevance = int(rel_table[rel_table['doc_id']==doc_number]['relevance'])\n",
    "            relevance_list.append(relevance)\n",
    "        else:\n",
    "            relevance_list.append(0)\n",
    "    DCG_result = compute_DCG_for_query(relevance_list)\n",
    "    ideal_relevance_list = rel_table['relevance'].tolist()\n",
    "    if len(ideal_relevance_list) >= cutoff:\n",
    "        ideal_relevance_list = ideal_relevance_list[:cutoff]\n",
    "    else:\n",
    "        extra = cutoff - len(ideal_relevance_list)\n",
    "        ideal_relevance_list.extend([0 for i in range(extra)])\n",
    "    iDCG_result = compute_DCG_for_query(ideal_relevance_list)\n",
    "    nDCG_result = DCG_result / iDCG_result\n",
    "    return nDCG_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ir_eval_metrics(query_table, rel_table):\n",
    "    P_cutoff, R_cutoff, nDCG_cutoff1, nDCG_cutoff2 = 10, 50, 10, 20\n",
    "    P_result = compute_num_of_rel_doc(\n",
    "        query_table, rel_table, P_cutoff) / P_cutoff\n",
    "    R_result = compute_num_of_rel_doc(\n",
    "        query_table, rel_table, R_cutoff) / len(rel_table)\n",
    "    R_precision = compute_num_of_rel_doc(\n",
    "        query_table, rel_table, len(rel_table)) / len(rel_table)\n",
    "    AP_result = compute_AP_for_query(\n",
    "        query_table, rel_table)\n",
    "    nDCG_result1 = compute_nDCG_for_query(\n",
    "        query_table, rel_table, nDCG_cutoff1)\n",
    "    nDCG_result2 = compute_nDCG_for_query(\n",
    "        query_table, rel_table, nDCG_cutoff2)\n",
    "    metrics_results = [P_result, R_result, R_precision, AP_result,\n",
    "                       nDCG_result1, nDCG_result2]\n",
    "    return metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ir_eval_result_file(ir_eval_results_list):\n",
    "    with open('ir_eval.csv', 'w') as f:\n",
    "        f.write(\"system_number,query_number,P@10,R@50,r-precision,AP,nDCG@10,nDCG@20\\n\")\n",
    "        for ir_eval_result in ir_eval_results_list:\n",
    "            metrics = ir_eval_result[2:]\n",
    "            metrics = ['{:.3f}'.format(metric) for metric in metrics]\n",
    "            ir_eval_result = ir_eval_result[:2]\n",
    "            ir_eval_result = [str(name) for name in ir_eval_result]\n",
    "            ir_eval_result.extend(metrics)\n",
    "            f.write(','.join(ir_eval_result) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ir_eval(sys_results, qrels):\n",
    "    ir_eval_results_list = []\n",
    "    for sys_num in pd.unique(sys_results['system_number']):\n",
    "        sys_table = sys_results[sys_results['system_number'] == sys_num]\n",
    "        ir_eval_results = []\n",
    "        for query_num in pd.unique(sys_table['query_number']):\n",
    "            query_table = sys_table[sys_table['query_number'] == query_num]\n",
    "            rel_table = qrels[qrels['query_id'] == query_num]\n",
    "            metrics_results = compute_ir_eval_metrics(query_table, rel_table)\n",
    "            ir_eval_results.append([sys_num, query_num] + metrics_results)\n",
    "        mean_ir_eval_result = np.mean(np.array(ir_eval_results)[:, 2:], axis=0).tolist()\n",
    "        ir_eval_results.append([sys_num, 'mean'] + mean_ir_eval_result)\n",
    "        ir_eval_results_list.extend(ir_eval_results)\n",
    "    write_ir_eval_result_file(ir_eval_results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_system_results(file_name):\n",
    "    sys_results = {}\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        header = f.readline()\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '').split(',')\n",
    "            sys_num, query_num = line[0], line[1]\n",
    "            if sys_num not in sys_results:\n",
    "                sys_results[sys_num] = {}\n",
    "            if query_num not in sys_results[sys_num]:\n",
    "                sys_results[sys_num][query_num] = {}\n",
    "            table = sys_results[sys_num][query_num]\n",
    "            if 'doc_number' not in table:\n",
    "                table['doc_number'] = []\n",
    "            if 'rank_of_doc' not in table:\n",
    "                table['rank_of_doc'] = []\n",
    "            if 'score' not in table:\n",
    "                table['score'] = []\n",
    "            table['doc_number'].append(int(line[2]))\n",
    "            table['rank_of_doc'].append(int(line[3]))\n",
    "            table['score'].append(float(line[4]))\n",
    "    return sys_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_qrels(file_name):\n",
    "    qrels = {}\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        header = f.readline()\n",
    "        for line in f:\n",
    "            line = line.replace('\\n', '').split(',')\n",
    "            query_num = line[0]\n",
    "            if query_num not in qrels:\n",
    "                qrels[query_num] = {}\n",
    "            table = qrels[query_num]\n",
    "            if 'doc_id' not in table:\n",
    "                table['doc_id'] = []\n",
    "            if 'relevance' not in table:\n",
    "                table['relevance'] = []\n",
    "            table['doc_id'].append(int(line[1]))\n",
    "            table['relevance'].append(int(line[2]))\n",
    "    return qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ir_eval(sys_results, qrels):\n",
    "    ir_eval_results_list = []\n",
    "    for sys_num in sys_results.keys():\n",
    "        ir_eval_results = []\n",
    "        for query_num in sys_results[sys_num].keys():\n",
    "            query_table = sys_results[sys_num][query_num]\n",
    "            rel_table = qrels[query_num]\n",
    "            metrics_results = compute_ir_eval_metrics(query_table, rel_table)\n",
    "            ir_eval_results.append([sys_num, query_num] + metrics_results)\n",
    "        ir_eval_result = np.array(ir_eval_results)[:, 2:]\n",
    "        ir_eval_result = ir_eval_result.astype(np.float)\n",
    "        mean_ir_eval_result = np.mean(ir_eval_result, axis=0).tolist()\n",
    "        ir_eval_results.append([sys_num, 'mean'] + mean_ir_eval_result)\n",
    "        ir_eval_results_list.extend(ir_eval_results)\n",
    "    return ir_eval_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ir_eval_result_file(ir_eval_results_list):\n",
    "    with open('ir_eval.csv', 'w') as f:\n",
    "        f.write(\"system_number,query_number,P@10,R@50,r-precision,AP,nDCG@10,nDCG@20\\n\")\n",
    "        for ir_eval_result in ir_eval_results_list:\n",
    "            metrics = ir_eval_result[2:]\n",
    "            metrics = ['{:.3f}'.format(metric) for metric in metrics]\n",
    "            ir_eval_result = ir_eval_result[:2]\n",
    "            ir_eval_result = [str(name) for name in ir_eval_result]\n",
    "            ir_eval_result.extend(metrics)\n",
    "            f.write(','.join(ir_eval_result) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ir_eval_metrics(query_table, rel_table):\n",
    "    P_cutoff, R_cutoff, nDCG_cutoff1, nDCG_cutoff2 = 10, 50, 10, 20\n",
    "    rel_num = len(rel_table['doc_id'])\n",
    "    P_result = compute_num_of_rel_doc(\n",
    "        query_table, rel_table, P_cutoff) / P_cutoff\n",
    "    R_result = compute_num_of_rel_doc(\n",
    "        query_table, rel_table, R_cutoff) / rel_num\n",
    "    R_precision = compute_num_of_rel_doc(\n",
    "        query_table, rel_table, rel_num) / rel_num\n",
    "    AP_result = compute_AP_for_query(\n",
    "        query_table, rel_table)\n",
    "    nDCG_result1 = compute_nDCG_for_query(\n",
    "        query_table, rel_table, nDCG_cutoff1)\n",
    "    nDCG_result2 = compute_nDCG_for_query(\n",
    "        query_table, rel_table, nDCG_cutoff2)\n",
    "    metrics_results = [P_result, R_result, R_precision, AP_result,\n",
    "                       nDCG_result1, nDCG_result2]\n",
    "    return metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_of_rel_doc(query_table, rel_table, cutoff):\n",
    "    num_of_rel_doc = 0\n",
    "    doc_nums = query_table['doc_number'][:cutoff]\n",
    "    rel_nums = rel_table['doc_id']\n",
    "    for doc_num in doc_nums:\n",
    "        if doc_num in rel_nums:\n",
    "            num_of_rel_doc += 1\n",
    "    return num_of_rel_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_AP_for_query(query_table, rel_table):\n",
    "    AP_result = 0\n",
    "    rel_docnums = rel_table['doc_id']\n",
    "    query_docnums = query_table['doc_number']\n",
    "    for index in range(len(query_docnums)):\n",
    "        relevance = 1 if query_docnums[index] in rel_docnums else 0\n",
    "        if relevance:\n",
    "            cutoff = index + 1\n",
    "            precision = compute_num_of_rel_doc(query_table, rel_table, cutoff) / cutoff\n",
    "            AP_result += relevance * precision\n",
    "    AP_result = AP_result / len(rel_docnums)\n",
    "    return AP_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DCG_for_query(relevance_list):\n",
    "    DCG_result = relevance_list[0]\n",
    "    for index in range(1, len(relevance_list)):\n",
    "        DCG_result += relevance_list[index] / np.log2(index+1)\n",
    "    return DCG_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nDCG_for_query(query_table, rel_table, cutoff):\n",
    "    query_docnums = query_table['doc_number'][:cutoff]\n",
    "    rel_docnums = rel_table['doc_id']\n",
    "    relevance_list = []\n",
    "    for index in range(len(query_docnums)):\n",
    "        doc_number = query_docnums[index]\n",
    "        if doc_number in rel_docnums:\n",
    "            idx = rel_docnums.index(doc_number)\n",
    "            relevance = rel_table['relevance'][idx]\n",
    "            relevance_list.append(relevance)\n",
    "        else:\n",
    "            relevance_list.append(0)\n",
    "    DCG_result = compute_DCG_for_query(relevance_list)\n",
    "    ideal_relevance_list = rel_table['relevance']\n",
    "    if len(ideal_relevance_list) >= cutoff:\n",
    "        ideal_relevance_list = ideal_relevance_list[:cutoff]\n",
    "    else:\n",
    "        extra = cutoff - len(ideal_relevance_list)\n",
    "        ideal_relevance_list.extend([0 for i in range(extra)])\n",
    "    iDCG_result = compute_DCG_for_query(ideal_relevance_list)\n",
    "    nDCG_result = DCG_result / iDCG_result\n",
    "    return nDCG_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_results = read_system_results('./system_results.csv')\n",
    "qrels = read_qrels('./qrels.csv')\n",
    "ir_eval_results_list = compute_ir_eval(sys_results, qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ir_eval_results(ir_eval_results_list):\n",
    "    system_mean_metrics = [row for row in ir_eval_results_list if row[1] == 'mean']\n",
    "    mean_metrics_dict = {'P@10': [], 'R@50': [], 'r-precision': [],\n",
    "                         'AP': [], 'nDCG@10': [], 'nDCG@20': []}\n",
    "    for row in system_mean_metrics:\n",
    "        for index, key in enumerate(mean_metrics_dict):\n",
    "            mean_metrics_dict[key].append(row[index+2])\n",
    "    system_metrics = [row for row in ir_eval_results_list if row[1] != 'mean']\n",
    "    metrics_dict = {'P@10': {}, 'R@50': {}, 'r-precision': {},\n",
    "                    'AP': {}, 'nDCG@10': {}, 'nDCG@20': {}}\n",
    "    for row in system_metrics:\n",
    "        sys_num = row[0]\n",
    "        for index, key in enumerate(metrics_dict):\n",
    "            if sys_num not in metrics_dict[key]:\n",
    "                metrics_dict[key][sys_num] = []\n",
    "            metrics_dict[key][sys_num].append(row[index+2])   \n",
    "    return mean_metrics_dict, metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ttest(mean_metrics_dict, metrics_dict):\n",
    "    inputs_list, t_statistics_list, pvalues_list = [], [], []\n",
    "    for key in mean_metrics_dict:\n",
    "        ranked_scores = sorted(set(mean_metrics_dict[key]), reverse=True)\n",
    "        largest_sys_nums = [str(i+1) for i, x in enumerate(mean_metrics_dict[key]) \n",
    "                            if x == ranked_scores[0]]\n",
    "        second_sys_nums = [str(i+1) for i, x in enumerate(mean_metrics_dict[key])\n",
    "                           if x == ranked_scores[1]]\n",
    "        t_statistics, pvalues, inputs = [], [], []\n",
    "        for largest_num in largest_sys_nums:\n",
    "            for second_num in second_sys_nums:\n",
    "                inputs.append((largest_num, second_num))\n",
    "                S1 = metrics_dict[key][largest_num]\n",
    "                S2 = metrics_dict[key][second_num]\n",
    "                t_statistic = stats.ttest_ind(S1, S2).statistic\n",
    "                pvalue = stats.ttest_ind(S1, S2).pvalue\n",
    "                t_statistics.append(t_statistic)\n",
    "                pvalues.append(pvalue)\n",
    "        t_statistic = round(sum(t_statistics) / len(t_statistics), 4)\n",
    "        pvalue = round(sum(pvalues) / len(pvalues), 4)\n",
    "        t_statistics_list.append(t_statistic)\n",
    "        pvalues_list.append(pvalue)\n",
    "        inputs_list.append(inputs)\n",
    "    return inputs_list, t_statistics_list, pvalues_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_metrics_dict, metrics_dict = parse_ir_eval_results(ir_eval_results_list)\n",
    "inputs_list, t_statistics_list, pvalues_list = perform_ttest(mean_metrics_dict, metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ttest_file(inputs_list, t_statistics_list, pvalues_list):\n",
    "    with open('ttest.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['info', 'P@10', 'R@50', 'r-precision',\n",
    "                         'AP', 'nDCG@10', 'nDCG@20'])\n",
    "        writer.writerow(['input'] + [str(inputs) for inputs in inputs_list])\n",
    "        t_statistics = ['{:.4f}'.format(t_statistic) for t_statistic in t_statistics_list]\n",
    "        writer.writerow(['t-stats'] + t_statistics)    \n",
    "        pvalues = ['{:.4f}'.format(pvalue) for pvalue in pvalues_list]   \n",
    "        writer.writerow(['p-value'] + pvalues)  \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_ttest_file(inputs_list, t_statistics_list, pvalues_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
